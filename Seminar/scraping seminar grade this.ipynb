{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Seminar\n",
    "By Clayton Boone and Pedro Romero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is web scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is a process that is used to extract data from websites to obtain needed data. Sometimes when we are faced with a problem and are required to create a model for analysis we are given data to use, but sometimes we are not given data and are forced to collect our own. Scraping allows us to get the data we need from a website by reading the website's HTML code. By reading the HTML code of a website we are able to see how the website is built and where the information is contatined. The HTML code for a website also allows us to determine the headers of the information we need. Web scraping allows us to gather information we need and to update our personal data with new data that may be loaded onto the website. Webscraping also allows us to retrieve all the necessary information we need without having to mess with or clean data that we are not interested in. Web scraping allows us to collect data from multiple sources and to combine information to build our data. With webscraping we are able to collect a very large amount of data that we my have not had at our disposal.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What tools do we have for web scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first web scraping tool we are going to talk about is Beautiful Soup. Beautiful Soup is used to pull data from an HTML or XML file. Beautiful Soup makes it easier to read these types of files so that we can see the setup and definitions for each type of file. Beautiful Soup also allows us to see where the information we want is located and what headers we should call for to get the wanted information. Beautiful Soup has a number of tools and commands that allow us to gather information from websites. The commands that we will discuss in this siminar include .get(), .content, .find, .find_all, get_text. Another tool we will discuss in this presentation is called Selenium which is used to open and travel through websites. Selenium is used to test the accessability of a website and to make sure that each route of an website is usable. Selenium can also be used to open up websites so that we can gather information from that website. Selenium allows us to open up and run websites by just using code and html\\xml headers and definitions. We will use selenium in this presentation to open up and gather information from websites.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will do a guided example that will show us how to scrape the seven day forecast from the website of the National Weather Service.The first thing we will need to do is request the content from the website we are wanting to scrape from. The .get() command gets the information from url and goes to that url. Next we will us Beautiful Soup to parse the HTML file of the National Weather Service so that we can view a complete and readable version of the HTML file. By printing out the variable labeled as weather_soup we will be able to view the HTML and will be able to see what headers are included and what infomation is contained in each header. Before starting any type of scraping it is important to inspect the HTML file and look at how the file is built and to see what the names of the id's and class'es are so that it is easier to select the data you are trying to scrape. In this example we are wanting to scrape all the data from the seven day forecast section of the website. By looking at the HTML file we can see that all the information that we need for the seven day forecast is contained in the class named seven-day-forecast. To get all the information for this class we use the find command which searches and returns the first instance of a class that is named seven-day-forecast. Looking futher into the class we are interested in we notice that each day is contained in a class called tombstone-container. To get the information in each tomstone-container we do a find_all search within the seven-day-forecast class to find all of the instances of the class tombstone-container. It is important to note that the find_all command returns a list and we can not directly gather information in that list. To collect text or data from that list we must iterate on each piece of the list and then use any command we want to use to extract the wanted data. Hence, the variable labeled as seven_list is a list. http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.Woor6KinHIU      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import io\n",
    "import re\n",
    "from math import floor\n",
    "import random\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "weather_page = requests.get('http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.WoW2W6inHIU')\n",
    "weather_soup = BeautifulSoup(weather_page.content, 'html.parser')\n",
    "seven_day = weather_soup.find(id = 'seven-day-forecast')\n",
    "seven_list = seven_day.find_all(class_ = 'tombstone-container')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next box of code shows how to gather wanted text and information once you have used a find_all statement to gather your wanted section of the HTML. For this first example we will use the first element in the seven_list to collect the day of the week, the discription of the weather for that day, the high or low temperature for that day, and the short description for that day.We collect the day of the week by using the find() command to find the first instance of the class named period-name and then use the get_text() command to get the text that is contained between the headers named period_name. We do the same procces to get the text for the description, temperature, and short description sections that are contained in the tombstone-container class. The only thing that is differnt when gathering the information is the name of the classes we use to get the information. To gather text for the discription section we first had to find the first instance of the work 'img' for each class then call the title section that is contained in img by using dis['title']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today Today: Increasing clouds, with a high near 51. East southeast wind 5 to 13 mph becoming west in the afternoon.  High: 51 °F IncreasingClouds\n"
     ]
    }
   ],
   "source": [
    "today = seven_list[0]\n",
    "period = today.find(class_ ='period-name').get_text()\n",
    "dis = today.find('img')\n",
    "short_dis = today.find(class_ = 'short-desc').get_text()\n",
    "tem = today.find(class_ = 'temp').get_text()\n",
    "print(period, dis['title'], tem, short_dis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next box of code shows the steps that are needed to create a dataframe that contains the day, the discription, the high or low temperature, and short desripction for each day of the week. First, we must iterate through each tombstone-container that is contained in the seven-day-forecast class. In each iteration we find the day of the week, description, short description, and temperature contained in each tombstone-container class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Today</th>\n",
       "      <th>Tonight</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>WednesdayNight</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>ThursdayNight</th>\n",
       "      <th>Friday</th>\n",
       "      <th>FridayNight</th>\n",
       "      <th>Saturday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Discription</th>\n",
       "      <td>Today: Increasing clouds, with a high near 51....</td>\n",
       "      <td>Tonight: A 30 percent chance of showers, mainl...</td>\n",
       "      <td>Wednesday: A 30 percent chance of showers, mai...</td>\n",
       "      <td>Wednesday Night: Partly cloudy, with a low aro...</td>\n",
       "      <td>Thursday: Mostly sunny, with a high near 54. B...</td>\n",
       "      <td>Thursday Night: Mostly clear, with a low aroun...</td>\n",
       "      <td>Friday: Mostly sunny, with a high near 56.</td>\n",
       "      <td>Friday Night: Mostly clear, with a low around 43.</td>\n",
       "      <td>Saturday: Mostly sunny, with a high near 57.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short Discription</th>\n",
       "      <td>IncreasingClouds</td>\n",
       "      <td>ChanceShowers</td>\n",
       "      <td>ChanceShowers</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Mostly Sunnyand Breezy</td>\n",
       "      <td>Mostly Clearand Breezythen PartlyCloudy</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>High: 51 °F</td>\n",
       "      <td>Low: 43 °F</td>\n",
       "      <td>High: 54 °F</td>\n",
       "      <td>Low: 44 °F</td>\n",
       "      <td>High: 54 °F</td>\n",
       "      <td>Low: 42 °F</td>\n",
       "      <td>High: 56 °F</td>\n",
       "      <td>Low: 43 °F</td>\n",
       "      <td>High: 57 °F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Today  \\\n",
       "Discription        Today: Increasing clouds, with a high near 51....   \n",
       "Short Discription                                   IncreasingClouds   \n",
       "Temp                                                     High: 51 °F   \n",
       "\n",
       "                                                             Tonight  \\\n",
       "Discription        Tonight: A 30 percent chance of showers, mainl...   \n",
       "Short Discription                                      ChanceShowers   \n",
       "Temp                                                      Low: 43 °F   \n",
       "\n",
       "                                                           Wednesday  \\\n",
       "Discription        Wednesday: A 30 percent chance of showers, mai...   \n",
       "Short Discription                                      ChanceShowers   \n",
       "Temp                                                     High: 54 °F   \n",
       "\n",
       "                                                      WednesdayNight  \\\n",
       "Discription        Wednesday Night: Partly cloudy, with a low aro...   \n",
       "Short Discription                                      Partly Cloudy   \n",
       "Temp                                                      Low: 44 °F   \n",
       "\n",
       "                                                            Thursday  \\\n",
       "Discription        Thursday: Mostly sunny, with a high near 54. B...   \n",
       "Short Discription                             Mostly Sunnyand Breezy   \n",
       "Temp                                                     High: 54 °F   \n",
       "\n",
       "                                                       ThursdayNight  \\\n",
       "Discription        Thursday Night: Mostly clear, with a low aroun...   \n",
       "Short Discription            Mostly Clearand Breezythen PartlyCloudy   \n",
       "Temp                                                      Low: 42 °F   \n",
       "\n",
       "                                                       Friday  \\\n",
       "Discription        Friday: Mostly sunny, with a high near 56.   \n",
       "Short Discription                                Mostly Sunny   \n",
       "Temp                                              High: 56 °F   \n",
       "\n",
       "                                                         FridayNight  \\\n",
       "Discription        Friday Night: Mostly clear, with a low around 43.   \n",
       "Short Discription                                       Mostly Clear   \n",
       "Temp                                                      Low: 43 °F   \n",
       "\n",
       "                                                       Saturday  \n",
       "Discription        Saturday: Mostly sunny, with a high near 57.  \n",
       "Short Discription                                  Mostly Sunny  \n",
       "Temp                                                High: 57 °F  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seven_title = []\n",
    "seven_dis = []\n",
    "seven_short_dis = []\n",
    "seven_temp = []\n",
    "for i in seven_list:\n",
    "    title = i.find(class_ = 'period-name').get_text()\n",
    "    seven_title.append(title)\n",
    "    dis = i.find('img')\n",
    "    seven_dis.append(dis['title'])\n",
    "    short = i.find(class_ = 'short-desc').get_text()\n",
    "    seven_short_dis.append(short)\n",
    "    temp = i.find(class_ = 'temp').get_text()\n",
    "    seven_temp.append(temp)\n",
    "chart = pd.DataFrame([seven_dis,seven_short_dis,seven_temp], index = ['Discription', 'Short Discription', 'Temp']\\\n",
    "                     ,columns = seven_title)\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using An API to Scrape Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will disscus how to use an API to gather our data. The website we will be scraping the data from is called the arxiv and we will use the API for the arxiv to gather our data. API stands for Application Programming Interface and is defined as a set of clearly defined methods of communication between various software coponents. The API makes it easier to navigate through the website and to search through the XXXneedXXX sections of the website you are using. Before using an API for a website it is very important to read the documentation for the website you desire to use and inform yourself on how the API for that website is set up. The documentation for the API of the arxiv website explains how each section/subject can be selected and how to choose how many articles you want to select. Here is a link to the API documentation for the arxiv website, https://arxiv.org/help/api/user-manual#_calling_the_api. The API for the arxiv limits the amount of articles you can scrape per subject. The API of the arxiv only allows us to pull 1,000 papers per subject. To pull a larger number of articles they suggest to us the OAI-PHM interface, which we will disscuss later in this presentation. In the code block below we are collecting the id, date published, title, subject, and authors for each first 10 papers in the section labeled stat.ap. The reason why we are only getting the first 10 papers is because the api is defaulted to only fetch the first 10 papers of each subject searched. We will explain how to search for more papers using the API in the next example. In this example we use urlopen to open the url we want to use and retrieve data from. Next we use Beautiful Soup to parse the HTML together so that we can view it and see the components of the HTML. First we collect all the information that is contained in all the headers labled entry that are contained in the HTML file. It is important to note that each entry represents the information avaliable for a single paper. Next, we interate through each item in the entry and collect the date, id, authors, title, and subject for each paper that is contained in the entry list. A dataframe that contains the information that was scraped from each entry is included below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dates</th>\n",
       "      <th>titles</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/0704.1711v2</td>\n",
       "      <td>2007-04-13T07:49:11Z</td>\n",
       "      <td>Dynamical Equilibrium, trajectories study in a...</td>\n",
       "      <td>Patrick Letrémy</td>\n",
       "      <td>Marie Cottrell</td>\n",
       "      <td>Patrice Gaubert</td>\n",
       "      <td>Joseph Rynkiewicz</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/0704.3474v1</td>\n",
       "      <td>2007-04-26T05:03:08Z</td>\n",
       "      <td>Missing Data: A Comparison of Neural Network a...</td>\n",
       "      <td>Fulufhelo V. Nelwamondo</td>\n",
       "      <td>Shakir Mohamed</td>\n",
       "      <td>Tshilidzi Marwala</td>\n",
       "      <td>None</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/0704.3862v1</td>\n",
       "      <td>2007-04-29T21:06:10Z</td>\n",
       "      <td>An Integrated Human-Computer System for Contro...</td>\n",
       "      <td>Tshilidzi Marwala</td>\n",
       "      <td>Monica Lagazio</td>\n",
       "      <td>Thando Tettey</td>\n",
       "      <td>None</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/0705.0569v1</td>\n",
       "      <td>2007-05-04T07:24:17Z</td>\n",
       "      <td>Mixed models for longitudinal left-censored re...</td>\n",
       "      <td>Rodolphe Thiébaut</td>\n",
       "      <td>Hélène Jacqmin-Gadda</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/0705.2515v1</td>\n",
       "      <td>2007-05-17T11:29:08Z</td>\n",
       "      <td>Finite Element Model Updating Using Bayesian A...</td>\n",
       "      <td>Tshilidzi Marwala</td>\n",
       "      <td>Lungile Mdlazi</td>\n",
       "      <td>Sibusiso Sibisi</td>\n",
       "      <td>None</td>\n",
       "      <td>stat.AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                 dates  \\\n",
       "0  http://arxiv.org/abs/0704.1711v2  2007-04-13T07:49:11Z   \n",
       "1  http://arxiv.org/abs/0704.3474v1  2007-04-26T05:03:08Z   \n",
       "2  http://arxiv.org/abs/0704.3862v1  2007-04-29T21:06:10Z   \n",
       "3  http://arxiv.org/abs/0705.0569v1  2007-05-04T07:24:17Z   \n",
       "4  http://arxiv.org/abs/0705.2515v1  2007-05-17T11:29:08Z   \n",
       "\n",
       "                                              titles                        0  \\\n",
       "0  Dynamical Equilibrium, trajectories study in a...          Patrick Letrémy   \n",
       "1  Missing Data: A Comparison of Neural Network a...  Fulufhelo V. Nelwamondo   \n",
       "2  An Integrated Human-Computer System for Contro...        Tshilidzi Marwala   \n",
       "3  Mixed models for longitudinal left-censored re...        Rodolphe Thiébaut   \n",
       "4  Finite Element Model Updating Using Bayesian A...        Tshilidzi Marwala   \n",
       "\n",
       "                      1                  2                  3 subjects  \n",
       "0        Marie Cottrell    Patrice Gaubert  Joseph Rynkiewicz  stat.AP  \n",
       "1        Shakir Mohamed  Tshilidzi Marwala               None  stat.AP  \n",
       "2        Monica Lagazio      Thando Tettey               None  stat.AP  \n",
       "3  Hélène Jacqmin-Gadda               None               None  stat.AP  \n",
       "4        Lungile Mdlazi    Sibusiso Sibisi               None  stat.AP  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url_api = \"http://export.arxiv.org/api/query?search_query=cat:stat.AP\"\n",
    "\n",
    "rd = urllib.request.urlopen(url_api)\n",
    "soup = BeautifulSoup(rd,\"xml\")\n",
    "entry = soup.findAll('entry')\n",
    "id_list =[]\n",
    "date_list = []\n",
    "title_list = []\n",
    "au_list = []\n",
    "sub_list = []\n",
    "for i in entry:\n",
    "    au_new= []\n",
    "    id_list.append(i.find('id').get_text())\n",
    "    date_list.append(i.find('published').get_text())\n",
    "    title_list.append(i.find('title').get_text())\n",
    "    cat = i.find('category')\n",
    "    sub_list.append(cat['term'])\n",
    "    for j in i.find_all('name'):\n",
    "        au_new.append(j.get_text())\n",
    "    au_list.append(au_new)\n",
    "paper_id = pd.DataFrame(id_list)\n",
    "date = pd.DataFrame(date_list)\n",
    "title = pd.DataFrame(title_list)\n",
    "authors = pd.DataFrame(au_list)\n",
    "subject = pd.DataFrame(sub_list)\n",
    "date.rename(columns={0:'dates'},inplace = True)\n",
    "paper_id.rename(columns= {0:'id'},inplace=True)\n",
    "title.rename(columns = {0:'titles'},inplace = True)\n",
    "subject.rename(columns={0:'subjects'},inplace = True)\n",
    "use_data = pd.concat([paper_id,date,title,authors,subject],axis = 1)\n",
    "use_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows an example where we can choose how many papers we want to scrape from each section. It is important to remember that the API only allows us to collect 1,000 papers from each subject so our max search should not be greater than 1,000. In this example we are selecting the first 3 papers from the first 3 entries in the category list, which are astro-ph.CO, astro-ph.EP, and astro-ph.GA. Included below is a dataframe that shows what information was pulled when collecting information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>titles</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/0901.0173v1</td>\n",
       "      <td>2009-01-01T10:33:18Z</td>\n",
       "      <td>Non-Minimal Quintessence With Nearly Flat Pote...</td>\n",
       "      <td>Anjan A Sen</td>\n",
       "      <td>Gaveshna Gupta</td>\n",
       "      <td>Sudipta Das</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>astro-ph.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/0901.0189v1</td>\n",
       "      <td>2009-01-01T18:36:01Z</td>\n",
       "      <td>Robust determination of the major merger fract...</td>\n",
       "      <td>C. López-Sanjuan</td>\n",
       "      <td>M. Balcells</td>\n",
       "      <td>C. E. García-Dabó</td>\n",
       "      <td>M. Prieto</td>\n",
       "      <td>D. Cristóbal-Hornillos</td>\n",
       "      <td>M. C. Eliche-Moral</td>\n",
       "      <td>D. Abreu</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>astro-ph.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/0901.0245v2</td>\n",
       "      <td>2009-01-02T16:05:48Z</td>\n",
       "      <td>Neutrino Masses, Dark Energy and the Gravitati...</td>\n",
       "      <td>R. Benton Metcalf</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>astro-ph.CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/0901.0282v2</td>\n",
       "      <td>2009-01-02T21:04:22Z</td>\n",
       "      <td>HAT-P-11b: A Super-Neptune Planet Transiting a...</td>\n",
       "      <td>G. Á. Bakos</td>\n",
       "      <td>G. Torres</td>\n",
       "      <td>A. Pál</td>\n",
       "      <td>J. Hartman</td>\n",
       "      <td>Géza Kovács</td>\n",
       "      <td>R. W. Noyes</td>\n",
       "      <td>D. W. Latham</td>\n",
       "      <td>...</td>\n",
       "      <td>A. Howard</td>\n",
       "      <td>S. Vogt</td>\n",
       "      <td>Gábor Kovács</td>\n",
       "      <td>J. Fernandez</td>\n",
       "      <td>A. Moór</td>\n",
       "      <td>R. P. Stefanik</td>\n",
       "      <td>J. Lázár</td>\n",
       "      <td>I. Papp</td>\n",
       "      <td>P. Sári</td>\n",
       "      <td>astro-ph.EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/0901.0482v1</td>\n",
       "      <td>2009-01-05T13:53:42Z</td>\n",
       "      <td>Physical collisions of moonlets and clumps wit...</td>\n",
       "      <td>Sebastien Charnoz</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>astro-ph.EP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                  date  \\\n",
       "0  http://arxiv.org/abs/0901.0173v1  2009-01-01T10:33:18Z   \n",
       "1  http://arxiv.org/abs/0901.0189v1  2009-01-01T18:36:01Z   \n",
       "2  http://arxiv.org/abs/0901.0245v2  2009-01-02T16:05:48Z   \n",
       "3  http://arxiv.org/abs/0901.0282v2  2009-01-02T21:04:22Z   \n",
       "4  http://arxiv.org/abs/0901.0482v1  2009-01-05T13:53:42Z   \n",
       "\n",
       "                                              titles                  0  \\\n",
       "0  Non-Minimal Quintessence With Nearly Flat Pote...        Anjan A Sen   \n",
       "1  Robust determination of the major merger fract...   C. López-Sanjuan   \n",
       "2  Neutrino Masses, Dark Energy and the Gravitati...  R. Benton Metcalf   \n",
       "3  HAT-P-11b: A Super-Neptune Planet Transiting a...        G. Á. Bakos   \n",
       "4  Physical collisions of moonlets and clumps wit...  Sebastien Charnoz   \n",
       "\n",
       "                1                  2           3                       4  \\\n",
       "0  Gaveshna Gupta        Sudipta Das        None                    None   \n",
       "1     M. Balcells  C. E. García-Dabó   M. Prieto  D. Cristóbal-Hornillos   \n",
       "2            None               None        None                    None   \n",
       "3       G. Torres             A. Pál  J. Hartman             Géza Kovács   \n",
       "4            None               None        None                    None   \n",
       "\n",
       "                    5             6     ...              15       16  \\\n",
       "0                None          None     ...            None     None   \n",
       "1  M. C. Eliche-Moral      D. Abreu     ...            None     None   \n",
       "2                None          None     ...            None     None   \n",
       "3         R. W. Noyes  D. W. Latham     ...       A. Howard  S. Vogt   \n",
       "4                None          None     ...            None     None   \n",
       "\n",
       "             17            18       19              20        21       22  \\\n",
       "0          None          None     None            None      None     None   \n",
       "1          None          None     None            None      None     None   \n",
       "2          None          None     None            None      None     None   \n",
       "3  Gábor Kovács  J. Fernandez  A. Moór  R. P. Stefanik  J. Lázár  I. Papp   \n",
       "4          None          None     None            None      None     None   \n",
       "\n",
       "        23     subjects  \n",
       "0     None  astro-ph.CO  \n",
       "1     None  astro-ph.CO  \n",
       "2     None  astro-ph.CO  \n",
       "3  P. Sári  astro-ph.EP  \n",
       "4     None  astro-ph.EP  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_1 = 'http://export.arxiv.org/help/api/user-manual#detailed_examples'\n",
    "rd_1 =urllib.request.urlopen(url_1)\n",
    "soup_2 = BeautifulSoup(rd_1,'xml')\n",
    "table = soup_2.findAll('table')\n",
    "tab_cat = table[-1]\n",
    "cati = []\n",
    "fin_cat = []\n",
    "tab_cat = tab_cat.findAll('td')\n",
    "for cat in tab_cat:\n",
    "    cati.append(cat.contents[0].strip())\n",
    "cou = len(cati)\n",
    "for i in range(cou):\n",
    "    if (i%2==1 or i == 0):\n",
    "        pass\n",
    "    else:\n",
    "        fin_cat.append(cati[i])\n",
    "extra_list = [\"econ.EM\",\"eess.AS\", \"eess.IV\", \"eess.SP\",\"q-fin.CP\", \"q-fin.EC\", \"q-fin.GN\", \"q-fin.MF\", \"q-fin.PM\",\\\n",
    "             \"q-fin.PR\", \"q-fin.RM\", \"q-fin.ST\", \"q-fin.TR\"]\n",
    "all_cat = fin_cat + extra_list\n",
    "data_list = []\n",
    "title = []\n",
    "new_title = []\n",
    "au_list_2 = []\n",
    "subject = []\n",
    "date = []\n",
    "for t in all_cat[:3]:#for all sub fields\n",
    "    url_3 = 'http://export.arxiv.org/api/query?search_query=cat:'+ t + '&start=0&max_results=3'\n",
    "    #shows first 1 papers for all subjects and subfields\n",
    "    rd_3 = urllib.request.urlopen(url_3)#open the url\n",
    "    soup_3 = BeautifulSoup(rd_3, 'html.parser')#allows me to read the xml for the url given\n",
    "    entry = soup_3.findAll('entry')#gind all the headers named entry and then output all the data inside\n",
    "    #the entry headers\n",
    "    for i in entry:#iterates through each entry header\n",
    "        au_new_2 = []\n",
    "        data_list.append(i.find('id').get_text())\n",
    "        date.append(i.find('published').get_text())\n",
    "        title.append(i.find('title').get_text())\n",
    "        cat_2 = i.find('category')\n",
    "        subject.append(cat_2['term'])\n",
    "        for j in i.find_all('name'):\n",
    "            au_new_2.append(j.get_text())\n",
    "        au_list_2.append(au_new_2)\n",
    "id_ = pd.DataFrame(data_list)\n",
    "paper_date = pd.DataFrame(date)\n",
    "paper_title = pd.DataFrame(title)\n",
    "paper_authors = pd.DataFrame(au_list_2)\n",
    "paper_subject = pd.DataFrame(subject)\n",
    "id_.rename(columns= {0:'id'},inplace=True)\n",
    "paper_title.rename(columns = {0:'titles'},inplace = True)\n",
    "paper_subject.rename(columns={0:'subjects'},inplace = True)\n",
    "paper_date.rename(columns={0:'date'},inplace = True)\n",
    "data_test = pd.concat([id_,paper_date,paper_title,paper_authors,paper_subject],axis = 1)\n",
    "data_test.head()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OAI to Scrape Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "Using the API to scrape data can be very useful when scraping a small amount of data, but when you are wanting to collect a large amount of data then the API may not be very useful. OAI stands for Open Archives Initiative and can be used to collect or harvest a large set of information from a website. It is important to read the documentation for the OAI you are using to see the set up and requirements that are needed to use the OAI. The link for the OAI documentation is http://www.openarchives.org/OAI/2.0/openarchivesprotocol.htm#ListMetadataFormats. For our semester project we wanted to collect all the articles that were available on the arxiv and had to figure out a way to web scrape that would allow us to collect a very large amount of data. After doing some research over some of the techniques that have been used to colect all the articles from the arxiv Tu converted code from another source to fit our needs. The code below shows how we collected all the articles for each section. First, we had to collect all the sections that are included in the arxiv. After collecting all the subjects we then collected all the papers from each subject. At the begining of the while loop you will notice a try except statment. This statement is in place for any pages that do not open on the first try. This stament forces a 30 second wait and then starts with the next item in the list. For each paper we collected the title, the date published, paper id, authors, and subject field. At the end of the code block below you will notice an if else statement. That if else statement determines if there is any section labeled ResumptionToken in the XML, and if there is a section labled ResumptionToken then there is more papers to collect and we use the url that includes the ResumptionToken from that section to collect more papers. This process is repeated till all papers are collected from that section. This code has been set to find all the papers in the econ section, but can be reset to find all the papers in the arxiv if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://export.arxiv.org/oai2?verb=ListRecords&set=econ&metadataPrefix=arXiv\n",
      "Got 503. Retrying after 10 seconds.\n",
      "http://export.arxiv.org/oai2?verb=ListRecords&set=econ&metadataPrefix=arXiv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oai:arXiv.org:0704.3649</td>\n",
       "      <td>2007-04-27</td>\n",
       "      <td>Quantile and Probability Curves Without Crossing</td>\n",
       "      <td>Chernozhukov Victor MIT;Fernandez-Val Ivan Bos...</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oai:arXiv.org:0704.3686</td>\n",
       "      <td>2007-04-27</td>\n",
       "      <td>Improving Estimates of Monotone Functions by R...</td>\n",
       "      <td>Chernozhukov Victor MIT;Fernandez-Val Ivan Bos...</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oai:arXiv.org:0708.1627</td>\n",
       "      <td>2007-08-12</td>\n",
       "      <td>Rearranging Edgeworth-Cornish-Fisher Expansions</td>\n",
       "      <td>Chernozhukov Victor;Fernandez-Val Ivan;Galicho...</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oai:arXiv.org:0806.4730</td>\n",
       "      <td>2008-06-28</td>\n",
       "      <td>Improving Point and Interval Estimates of Mono...</td>\n",
       "      <td>Chernozhukov Victor;Fernandez-Val Ivan;Galicho...</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oai:arXiv.org:0904.0951</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>Inference on Counterfactual Distributions</td>\n",
       "      <td>Chernozhukov Victor;Fernandez-Val Ivan;Melly B...</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       doi        date  \\\n",
       "0  oai:arXiv.org:0704.3649  2007-04-27   \n",
       "1  oai:arXiv.org:0704.3686  2007-04-27   \n",
       "2  oai:arXiv.org:0708.1627  2007-08-12   \n",
       "3  oai:arXiv.org:0806.4730  2008-06-28   \n",
       "4  oai:arXiv.org:0904.0951  2009-04-06   \n",
       "\n",
       "                                               title  \\\n",
       "0   Quantile and Probability Curves Without Crossing   \n",
       "1  Improving Estimates of Monotone Functions by R...   \n",
       "2    Rearranging Edgeworth-Cornish-Fisher Expansions   \n",
       "3  Improving Point and Interval Estimates of Mono...   \n",
       "4          Inference on Counterfactual Distributions   \n",
       "\n",
       "                                             authors category  \n",
       "0  Chernozhukov Victor MIT;Fernandez-Val Ivan Bos...     econ  \n",
       "1  Chernozhukov Victor MIT;Fernandez-Val Ivan Bos...     econ  \n",
       "2  Chernozhukov Victor;Fernandez-Val Ivan;Galicho...     econ  \n",
       "3  Chernozhukov Victor;Fernandez-Val Ivan;Galicho...     econ  \n",
       "4  Chernozhukov Victor;Fernandez-Val Ivan;Melly B...     econ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://export.arxiv.org/oai2?verb=ListSets\"\n",
    "u = urllib.request.urlopen(url, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8')\n",
    "text = f.read()\n",
    "soup = BeautifulSoup(text, 'xml')\n",
    "all_cat = [sp.text for sp in soup.findAll(\"setSpec\")]\n",
    "\n",
    "f = open(\"all_cat_v01.txt\", \"w\")\n",
    "f.write(\",\".join(all_cat))\n",
    "f.close()\n",
    "def scrape(cat):\n",
    "    \n",
    "    # Initialization\n",
    "    df = pd.DataFrame(columns=(\"doi\", \"date\", \"title\", \"authors\", \"category\"))\n",
    "    base_url = \"http://export.arxiv.org/oai2?verb=ListRecords&\"\n",
    "    url = base_url + \"set={}&metadataPrefix=arXiv\".format(cat)\n",
    "    \n",
    "    # while loop in order to loop through all the resutls\n",
    "    while True:\n",
    "        # print url to keep track of stuff\n",
    "        print(url)\n",
    "        # accessing the url\n",
    "        try:\n",
    "            u = urllib.request.urlopen(url, data = None)\n",
    "        except HTTPError as e:\n",
    "            # Incase of some error that require us to wait\n",
    "            if e.code == 503:\n",
    "                to = int(e.hdrs.get(\"retry-after\", 30))\n",
    "                print(\"Got 503. Retrying after {0:d} seconds.\".format(to))\n",
    "                time.sleep(to)\n",
    "                continue # Skip this loop, continue to the next one\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # reading the file\n",
    "        f = io.TextIOWrapper(u,encoding='utf-8')\n",
    "        text = f.read()\n",
    "        soup = BeautifulSoup(text, 'xml')\n",
    "\n",
    "        # collecting the data\n",
    "        for record in soup.findAll(\"record\"):\n",
    "            try:\n",
    "                doi = record.find(\"identifier\").text\n",
    "            except:\n",
    "                doi = np.nan\n",
    "            \n",
    "            try:\n",
    "                date = record.find(\"created\").text\n",
    "            except:\n",
    "                date = np.nan\n",
    "            \n",
    "            try:\n",
    "                title = record.find(\"title\").text\n",
    "            except:\n",
    "                title = np.nan\n",
    "            \n",
    "            try:\n",
    "                authors = \";\".join([author.get_text(\" \") for author in record.findAll(\"author\")])\n",
    "            except:\n",
    "                authros = np.nan\n",
    "            \n",
    "            try:\n",
    "                category = record.find(\"setSpec\").text\n",
    "            except:\n",
    "                category = np.nan\n",
    "                \n",
    "            df = df.append({\"doi\":doi, \"date\":date, \"title\":title, \"authors\":authors, \"category\":category}, ignore_index=True)\n",
    "                \n",
    "\n",
    "        # Seeing if there is still data\n",
    "\n",
    "        token = soup.find(\"resumptionToken\")\n",
    "        if token is None or token.text is None:\n",
    "            break\n",
    "        else:\n",
    "            url = base_url + \"resumptionToken=%s\"%(token.text)\n",
    "        \n",
    "    return(df)\n",
    "master_df = pd.DataFrame(columns=(\"doi\", \"date\", \"title\", \"authors\", \"category\"))\n",
    "# for i in all_cat:\n",
    "#     print(\"----------------\",i,\"-------------------\")\n",
    "df = scrape('econ')\n",
    "master_df = master_df.append(df, ignore_index = True)\n",
    "master_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is included to show the make up of the XML and to show why we choose the headers that we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_oai = 'http://export.arxiv.org/oai2?verb=ListRecords&set=cs&metadataPrefix=arXiv'\n",
    "u = urllib.request.urlopen(url_oai, data = None)\n",
    "f = io.TextIOWrapper(u,encoding='utf-8')\n",
    "text = f.read()\n",
    "soup_oai_test = BeautifulSoup(text, 'xml')\n",
    "# soup_oai_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selenium is a collection of open source APIs which are used to automate the testing of a website. Selenium can be used with a number of browsers, but for this presentation we will use the FireFox browser. Selenium allows us to test websites and to make sure that we can travel within a website without any trouble. In this presentation we used the Selenium webdriver which allows us to use a browser to connect to websites we would like to open. Selenium uses a get command to go to the wanted website that the user would like to use. On this first example we used the Facebook URL in the get command so that the webdriver would open up a firefox browser. In this example we will use the webdriver to log into facebook. In order to type in the username we would like to use we must first tell the webdriver where the username space is located. We find the location of the username space by left clicking the username space on the facebook website and looking at the HTML file. By looking at the HTML file we can see that the username space is contained within the id named 'email', so we use the find_element_by_id command to find the location of the username space and then use the send_key command to type in the username that we want to use into the username blank. We use the same steps to type in the wanted password, but insted of email we use 'pass' as the id because that is where the password blank is located. To click the submit button we use the send_keys command but use KEYS.RETURN within that command to submit the username and password. When you are done using the webdriver to travel through the websites it is very important to close the driver, this can be done by using the .close() command.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"im not gonna use my real user name\"\n",
    "pwd = \"im not gonna use my own password\"\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://www.facebook.com\")\n",
    "assert \"Facebook\" in driver.title\n",
    "elem = driver.find_element_by_id(\"email\")\n",
    "elem.send_keys(user)\n",
    "elem = driver.find_element_by_id(\"pass\")\n",
    "elem.send_keys(pwd)\n",
    "elem.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this next example we open up a firefox browser and the load the Google website. We then search the word hockey in the search browser and click search. The next page that we are brought to is the page that contains all the results for the hockey search. We then tell the webdriver to select the wiki page for hockey and then select the inline section that is included in the hockey wiki page. We then selected the main source URL for the inline hockey section and then used Beautiful Soup to extract all the text from the main inline source. When using Selenium to travel through websites it is important to include wait statements which requires each action to delay itself until the wait has been met. If you do not use wait statements in your code there is a chance you will get an error because the code will run too fast and will not be able to open the pages you want to open because they may not be able to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roller in-line hockey is a team sport played on a wood, asphalt, cement or sport tile surface, in which players use a hockey stick to shoot a hard plastic hockey puck into their opponent's goal to score points.[1] It is considered a contact sport but body checking is prohibited. However, there are exceptions to that with the NRHL which involves fighting. Inline hockey teams are composed of up to four lines of players including two forwards and two defensemen on each line. There are five players including the goalie from each team on the rink at a time. It is the goalie's job to prevent the other team's players from scoring. Teams normally consist of 16 players that sit on the bench until it is their turn to play.[2] As the name suggests it is played on inline skates.\n",
      "Inline hockey is a very fast paced and free flowing game, this is because it does not have the same rules as ice hockey. There are no blue lines or defensive zones in roller hockey unlike ice hockey. This means that, according to most rule codes, there are no offsides or icings that can occur during game play; this along with fewer players on the rink allows for faster game play.[2] There are traditionally two 20-minute periods or four 10-minute periods with a stopped clock.\n",
      "In the United States, the highest governing body for the sport is USA Roller Sports which is commonly referred to as USARS. USARS is credited with the development of the present day rules and regulations that is used throughout multiple tournament series. They organize tournaments across the United States but they are not the only tournament provider. Some of the other independent tournament providers include Amateur Athletic Union, North American Roller Championships, and the Torhs 2 Hot 4 Ice tournament series.[2]\n",
      "Internationally, inline hockey is represented by two different unions, the Fédération Internationale de Roller Sports and the International Ice Hockey Federation. Each organizes its own annual World Championships.\n",
      "\n",
      "\n",
      "Some of the earliest video evidence of the sport is newsreel footage from the Giornale Luce taken in Vienna, Austria in 1938.[3] The video shows players using inline skates with five metal wheels and a front wheel brake. Each team has four skaters plus a netminder. They are using ice hockey sticks, with taped blades, and the goals closely resemble ice hockey goals of the wire-mesh type common in Europe around that time. The game is being played with a ball on a rectangular outdoor court, which appears to be asphalt.\n",
      "In the United States, the USA Roller Sports (USARS) predecessor organization was the Roller Skating Rink Operators Association (RSROA). In 1940 the RSROA published a set of roller hockey rules drawn from a booklet by the National Hockey League (NHL) which was designed to grow interest in playing hockey on roller skates. However, because of the intervention of World War II, the organization of roller hockey tournaments did not receive significant development until after this war in the late 1940s. At first skating club interest was confined to the northern tier of the United States, including the bordering Canadian cities. Puck roller hockey's spread in popularity during that period was helped along by the attention of local commercial television, which was getting its start and in desperate need for events to fill air time. The increased interest in the sport led in 1959 to the selection of a National Puck Hockey Committee to formulate special rules for the performance of puck hockey in the variety of rink sizes available to roller skates. The American Roller Hockey Association (ARHA) was formed with Joe Spillman, a roller rink operator from San Antonio, Texas as its first Commissioner. Under Spillman's direction, the sport of hockey on roller skates grew rapidly throughout the United States.\n",
      "During the 1960 RSROA National Roller Skating Championships held in Little Rock, Arkansas, exhibition games for ball and puck roller hockey were held. Following these Nationals, the first full competitive season officially began in North America for roller hockey. This, of course, had puck roller hockey entirely performed on quad skates, for at that time there were no in-line skates available. State and Regional competitions determined the teams that would move on to the North American Championships.\n",
      "In 1962 at Pershing Auditorium in Lincoln, Nebraska both Ball and Puck Hockey took part in the North American Championships, with the Arcadia Wildcats from Detroit, Michigan becoming the first Puck Hockey national champions on quad skates. Inline skates were not commercially available during that era.\n",
      "On 1 September 1965, during their semi-annual board meeting, the RSROA installed puck hockey as an equal and separate division of roller hockey, which included ball hockey, a format most popular in Europe and South America. It was decided that both ball and puck hockey would compete under the same rules and award separate gold medal winners. Budd Van Roekel, RSROA president, was quoted in the January 1965 issue of Skate Magazine, \"We believe this move will spark further growth of our roller hockey program. While we recognize the popularity of the international ball-and-cane version of hockey, we also realize that thousands of potential United States and Canadian players are more familiar with the Canadian stick-and-puck type sport. We see no reason why the two versions of the sport cannot grow side by side.\"\n",
      "The 1966 North American Championships marked the return of puck hockey after a four-year hiatus. The final game was a nail biter and the crowd appreciated the fast pace and excitement of puck hockey. The final game was between the Canadians of Windsor, Ontario and the Wildcats of Detroit, Michigan, the defending champions from 1962. The score seesawed between the two teams and was finally decided in favor of the Canadians with a final score of 5 to 3. The win gave the Canadian team their only gold medal for the whole North American Championships. One Canadian team player was quoted in the 1966 Fall issue of Skate Magazine, \"We simply had to win the (puck) hockey championships, otherwise our fathers wouldn’t allow us to return home.\"\n",
      "Another milestone occurred for puck roller hockey in 1977, when the North American Puck Hockey Championship was held in a venue away from ball hockey for the first time. The 1977 puck championships were staged in Houston, Texas to large crowds and a great amount of publicity, as fourteen newspapers and television stations covered the event. The year 1977 was also a milestone for women with this championship marking the debut of a women’s hockey national championship.\n",
      "The very first inline roller hockey team to earn a USA National Championship title did so at a USA Roller Sports National Championship held in San Diego in July 1993. At the previous 1992 USARS National Championships, also staged in San Diego, the San Diego Hosers won the Senior Gold Division title wearing their customary quad roller skates. As of that time, the Hosers manager/coach Paul Chapey felt that while inline skates were obviously faster, the advantage was to quad skates because of their assumed greater maneuverability. Some teams and individual players at the 1992 Nationals had been equipped with inline skates, but perhaps had not yet mastered their new vehicles. During the ensuing year, Paul Chapey became an inline convert and the San Diego Hosers came back to the USAC/RS Nationals in 1993 entirely on inline skates and recaptured their national title. This significant event took place at least a year before all the other major roller inline hockey organizations were even in existence, including National Inline Hockey Association (NIHA), USA Hockey InLine, North American Roller Hockey Championships (NARCh) and American Inline Roller Hockey Series (AIRHS).\n",
      "USA Roller Sports, under the auspices of Fédération Internationale de Roller Sports (FIRS), established and hosted the first World Inline Roller Hockey Championships for men at the Odeum Arena in Villa Park, Illinois (a suburb of Chicago) in 1995. USA Roller Sports established the first Inline Hockey World Championships for Juniors, again in Chicago in 1996, following the USA National Championships. The first World Inline Hockey Championships for Women occurred under sponsorship of USA Roller Sports in Rochester, New York in 2002. Since the introduction of these events, FIRS National Federations around the world have annually perpetuated inline world championships. USA (Ice) Hockey and International Ice Hockey Federation (IIHF) began their men’s InLine Hockey World Championship in 1996, after the first such world championship by FIRS and has yet to organize a women’s inline hockey world tournament or one for juniors.\n",
      "In March 2002, the United States Olympic Committee (USOC) Membership and Credentials Committee officially reaffirmed that USA Roller Sports as the governing body for inline hockey in the United States, which continues to this day. This determination was based on a conclusion by the USOC that internationally the sport of inline hockey is recognized as a discipline of roller sports. Then, as now, USA Roller Sports is a member in good standing of Federation International de Roller Sports (\"FIRS\"), the international federation for roller sports as recognized by the International Olympic Committee, and FIRS is also recognized by the Pan American Sports Organization (PASO) as the controlling international federation for inline hockey, a sport of the Pan American Games.\n",
      "Inline roller hockey was introduced to the World Games for the first time in 2005, an International Olympic Committee (IOC) sanctioned event under the jurisdiction of the International World Games Association (IWGA), an affiliate of the General Association of International Sports Federations (GAISF). The United States won the Gold Medal, with Canada taking the Silver and Switzerland the Bronze Medal. Inline roller hockey replaced rink hockey (ball and cane) on the World Games program for Duisburg, Germany at the 2005 quadrennial World Games. Rink roller hockey had been part of the World Games since its first organization in 1979 at Santa Clara, California, as have the other disciplines of roller sports.\n",
      "During the General Assembly of the IWGA, which took place in Madrid on 14 May 2003, the IWGA unanimously agreed that inline roller hockey was the responsibility of FIRS and that this variant form of roller hockey would be included on the program of the 2005 World Games in place of the previous format. This same scenario had previously played out before the Pan American Sports Organization in 1999, when inline hockey made its first appearance at the Pan American Games in Canada, and repeated again four years later in the Dominican Republic. PASO extends continued recognition of the inline hockey under the jurisdiction of FIRS.\n",
      "National Roller Hockey League is a professional league, founded in 2014. The NRHL began its inaugural season 20 February 2015. The NRHL games consist of 3 15-minute periods, with 10 minute intermissions. It differs from professional ice hockey with rules like no fighting, no offsides, and no icing. The players in the NRHL pay nothing to play, with compensation opportunities available in the inaugural season.\n",
      "MLRH (Major League Roller Hockey), is played in the United States and Europe. It consists of East and West Coast divisions, and the season is played from October to March with finals being held in either Europe or the USA. This is the only full check inline league in the world and it has a $10,000 championship purse. It has similar rules as the NHL, with some exceptions and only having two 17 min periods and in the \"Super\" League, 4 x 12 minute quarters. MLRH has offside and icing rules as well as allowing players to have a single fight per game.\n",
      "There are hockey teams from all over the country and play for inline travel hockey teams and they are trying to make it to the national championships for the North American roller hockey championships.\n",
      "Although inline hockey appears, at first glance, to simply be ice hockey on inline skates, this single change ramifies through the rest of the game, resulting in important differences between the two sports.\n",
      "Inline hockey is typically played at room temperature on a surface that, rather than being made from (frozen) water, is kept dry to protect the bearings in the skate wheels. Several surface materials are used, including plastic tiles (sometimes known as sport-court flooring), wood, and sealed concrete; in general, surfaces try to balance the ability of wheels to grip against the ability of the puck to slide freely. None of these surfaces, however, are as smooth as ice; as a result, the puck is made of a much lighter plastic material, and rests on small nylon or poly-plastic nubs to reduce friction with the rink surface.\n",
      "Besides these equipment differences, inline hockey is generally a less physical sport. Most leagues punish fighting harshly, and body checking is usually a penalty. Leagues generally require players to wear full face masks, but otherwise, players tend to wear lighter clothes and less protective padding.\n",
      "There are other rules differences as well. Each team fields only four skaters (plus a goaltender), rather than ice hockey's five. Many leagues do not stop play for icing. Offside rules are generally looser as well; originally, a few leagues would call offside only on the center line, presently, every rule book omits the rule entirely.\n",
      "Inline hockey is a contact sport. Although body checks are usually not allowed, injuries can still be a common occurrence. Protective equipment is highly recommended and is enforced in all competitive situations. This usually includes a helmet (cage worn if certain age), elbow pads, protective gloves, athletic cup, shin pads, and skates at the very least. In addition, goaltenders use different gear, (optionally) a neck guard, chest/arm protector, blocker, catch glove, and leg pads.\n",
      "One of the most fundamental differences between the IIHF and FIRS-sanctioned versions of inline hockey lies within the dimensions of the net. The IIHF simply retains the use of ice hockey nets. However the FIRS rulebook substitutes the traditional ice hockey cage for a lower and narrower model patterned after the one used in rink hockey, the FIRS' flagship sport, however most FIRS leagues in the United States and Canada opt for the more popular and common ice hockey nets.\n",
      "While the general characteristics of the game are the same wherever it is played, the exact rules depend on the particular code of play being used. The most important code is that of the Comité International Roller In-Line Hockey (CIRILH), an organization and discipline of the Fédération Internationale de Roller Sports (FIRS)[4]\n",
      "Inline hockey is played on an inline hockey rink. During normal play, there are five players per side on the floor at any time, one of them being the goaltender, each of whom is on inline hockey skates. The objective of the game is to score goals by shooting a hard plastic disc, the puck, into the opponent's goal net, which is placed at the opposite end of the rink. The players may control the puck using a long stick with a blade that is commonly curved at one end.\n",
      "Players may also redirect the puck with any part of their bodies, subject to certain restrictions. Players may not hold the puck in their hand and are prohibited from using their hands to pass the puck to their teammates, unless they are in the defensive zone. Players are also prohibited from kicking the puck into the opponent's goal, though unintentional redirections off the skate are permitted. Players may not intentionally bat the puck into the net with their hands.\n",
      "The four players other than the goaltender are typically divided into two forwards and two defencemen. The forward positions consist of a center and a winger. The defencemen usually stay together as a pair generally divided between left and right. A substitution of an entire unit at once is called a line change. Teams typically employ alternate sets of forward lines and defensive pairings when shorthanded or on a power play. Substitutions are permitted at any time during the course of the game, although during a stoppage of play the home team is permitted the final change. When players are substituted during play, it is called changing on the fly.\n",
      "The boards surrounding the floor help keep the puck in play and they can also be used as tools to play the puck. Players are not permitted to \"bodycheck\" opponents into the boards as a means of stopping progress. The referees and the outsides of the goal are \"in play\" and do not cause a stoppage of the game when the puck or players are influenced (by either bouncing or colliding) into them. Play can be stopped if the goal is knocked out of position. Play often proceeds for minutes without interruption. When play is stopped, it is restarted with a faceoff. Two players \"face\" each other and an official drops the puck to the floor, where the two players attempt to gain control of the puck. Markings on the floor indicate the locations for the \"faceoff\" and guide the positioning of players.\n",
      "There is one major rule of play in inline hockey that limit the movement of the puck: the puck going out of play. The puck goes \"out of play\" whenever it goes past the perimeter of the rink (onto the player benches, over the \"glass,\" or onto the protective netting above the glass) and a stoppage of play is called by the officials using whistles. It also does not matter if the puck comes back onto the playing surface from those areas as the puck is considered dead once it leaves the perimeter of the rink.\n",
      "Under FIRS rules, each team may carry a maximum of 14 players and two goaltenders on their roster. The players are usually divided into three lines of two forwards, two pairs of defenceman, and two extra skaters.\n",
      "For most penalties, the offending player is sent to the \"penalty box\" and his team has to play with one less skater for a short amount of time. Minor penalties last for two minutes, major penalties last for five minutes, and a double minor penalty is two consecutive penalties of two minutes duration. A single Minor penalty may be extended by a further two minutes for drawing blood from the victimized player. The team that has taken the penalty is said to be playing shorthanded while the other team is on a power play.\n",
      "A two-minute minor penalty is often called for lesser infractions such as tripping, elbowing, roughing, high-sticking, delay of the game, too many players on the rink, boarding, illegal equipment, holding, interference, hooking, slashing, butt-ending (striking an opponent with the knob of the stick—a very rare penalty) or cross-checking. A minor is also assessed for diving, where a player embellishes a hook or trip. More egregious fouls may be penalized by a four-minute double-minor penalty, particularly those which cause injury to the victimized player. These penalties end either when the time runs out or the other team scores on the power play. In the case of a goal scored during the first two minutes of a double-minor, the penalty clock is set down to two minutes upon a score effectively expiring the first minor penalty. Five-minute major penalties are called for especially violent instances of most minor infractions that result in intentional injury to an opponent, or when a \"minor\" penalty results in visible injury (such as bleeding), as well as for fighting. Major penalties are always served in full; they do not terminate on a goal scored by the other team.\n",
      "Some varieties of penalties do not always require the offending team to play a man short. Concurrent five-minute major penalties in the FIRS usually result from fighting. In the case of two players being assessed five-minute fighting majors, they both serve five minutes without their team incurring a loss of player (both teams still have a full complement of players on the floor). This differs with two players from opposing sides getting minor penalties, at the same time or at any intersecting moment, resulting from more common infractions. In that case, both teams will have only three skating players (not counting the goaltender) until one or both penalties expire (if one expires before the other, the opposing team gets a power play for the remainder); this applies regardless of current pending penalties, though in the FIRS, a team always has at least two skaters on the rink. Ten-minute misconduct penalties are served in full by the penalized player, but his team may immediately substitute another player on the floor unless a minor or major penalty is assessed in conjunction with the misconduct (a two-and-ten or five-and-ten). In that case, the team designates another player to serve the minor or major; both players go to the penalty box, but only the designee may not be replaced, and he is released upon the expiration of the two or five minutes, at which point the ten-minute misconduct begins. In addition, game misconducts are assessed for deliberate intent to inflict severe injury on an opponent (at the officials' discretion), or for a major penalty for a stick infraction or repeated major penalties. The offending player is ejected from the game and must immediately leave the playing surface (he does not sit in the penalty box); meanwhile, if a minor or major is assessed in addition, a designated player must serve out that segment of the penalty in the box (similar to the above-mentioned \"two-and-ten\"). In some rare cases, a player may receive up to nineteen minutes in penalties for one string of plays. This could involve receiving a four-minute double minor penalty, getting in a fight with an opposing player who retaliates, and then receiving a game misconduct after the fight. In this case, the player is ejected and two teammates must serve the double-minor and major penalties.\n",
      "A player who is tripped, or illegally obstructed in some way, by an opponent on a breakaway – when there are no defenders except the goaltender between him and the opponent's goal – is awarded a penalty shot, an attempt to score without opposition from any defenders except the goaltender. A penalty shot is also awarded for a defender other than the goaltender covering the puck in the goal crease, a goaltender intentionally displacing his own goal posts during a breakaway to avoid a goal, a defender intentionally displacing his own goal posts when there is less than two minutes to play in regulation time or at any point during overtime, or a player or coach intentionally throwing a stick or other object at the puck or the puck carrier and the throwing action disrupts a shot or pass play.\n",
      "Officials also stop play for puck movement violations, such as using one's hands to pass the puck in the offensive end, but no players are penalized for these offenses. The sole exceptions are deliberately falling on or gathering the puck to the body, carrying the puck in the hand, and shooting the puck out of play in one's defensive zone (all penalized two minutes for delay of game).\n",
      "A typical game of inline hockey has two officials on the floor, charged with enforcing the rules of the game. There are typically two referees who call goals and penalties. Due to not having offside and icing violations, there usually are no linesmen used. On-ice officials are assisted by off-ice officials who act as time keepers, and official scorers.\n",
      "Officials are selected by the league for which they work. Amateur hockey leagues use guidelines established by national organizing bodies as a basis for choosing their officiating staffs. In North America, the national organizing bodies USA Roller Sports and Canada Inline approve officials according to their experience level as well as their ability to pass rules knowledge and skating ability tests.\n",
      "Offensive tactics include improving a team's position on the floor by advancing the puck towards the opponent's goal. FIRS rules have no offside or two-line passes. A player may pass the puck to a player on any spot on the floor. Offensive tactics, are designed ultimately to score a goal by taking a shot. When a player purposely directs the puck towards the opponent's goal, he or she is said to \"shoot\" the puck.\n",
      "A deflection is a shot which redirects a shot or a pass towards the goal from another player, by allowing the puck to strike the stick and carom towards the goal. A one-timer is a shot which is struck directly off a pass, without receiving the pass and shooting in two separate actions. Headmanning the puck, also known as cherry-picking, the stretch pass or breaking out, is the tactic of rapidly passing to the player farthest down the floor.\n",
      "A team that is losing by one or two goals in the last few minutes of play will often elect to pull the goalie; that is, remove the goaltender and replace him or her with an extra attacker on the floor in the hope of gaining enough advantage to score a goal. However, it is an act of desperation, as it sometimes leads to the opposing team extending their lead by scoring a goal in the empty net.\n",
      "A delayed penalty call occurs when a penalty offense is committed by the team that does not have possession of the puck. In this circumstance the team with possession of the puck is allowed to complete the play; that is, play continues until a goal is scored, a player on the opposing team gains control of the puck, or the team in possession commits an infraction or penalty of their own. Because the team on which the penalty was called cannot control the puck without stopping play, it is impossible for them to score a goal, however, it is possible for the controlling team to mishandle the puck into their own net. In these cases the team in possession of the puck can pull the goalie for an extra attacker without fear of being scored on. If a delayed penalty is signaled and the team in possession scores, the penalty is still assessed to the offending player, but not served.\n",
      "One of the most important strategies for a team is their forecheck. Forechecking is the act of attacking the opposition in their defensive zone. Forechecking is an important part of roller hockey, because certain leagues and rules allow teams that have possession of the puck to sit behind their net and wait until they are pressured before having to advance the puck. Each team will use their own unique forecheck system but the main ones are: 1–1–2, 1–2–1, and 1–3. The 1–1–2 is the most basic forecheck system where one forward will go in deep and pressure the opposition's defencemen, the second forward stays in the slot, and the two defencemen high. The 1–3 is the most defensive forecheck system where one forward will apply pressure to the puck carrier in the opponent's zone and the other three players stand basically in a line in their defensive zone in hopes the opposition will skate into one of them.\n",
      "Roller hockey is unique in that its rules resemble more of a basketball/soccer/lacrosse strategy in many ways versus a traditional ice hockey approach.\n",
      "There are many other little tactics used in the game of hockey. Pinching is the term used when a defenceman pressures the opposition's winger in the offensive zone when they are breaking out, attempting to stop their attack and keep the puck in the offensive zone. A saucer pass is a pass used when an opposition's stick or body is in the passing lane. It is the act of raising the puck over the obstruction and having it land on a teammates' stick.\n",
      "A \"deke,\" short for \"decoy,\" is a feint with the body and/or stick to fool a defender or the goalie. Due to the increased room and lack of body checking, many inline hockey players have picked up the skill of \"dangling,\" which is more fancy deking and requires more stick handling skills. Some of the more impressive \"dekes\" or \"dangles\" include the toe-drag, the Pavel Datsyuk, the back hand toe-drag, and the spin-o-rama.\n",
      "Fighting is prohibited in the rules. It does happen rarely, however. Players used to an ice hockey mentality fight to demoralize the opposing players while exciting their own, as well as settling personal scores. A fight will also break if one of the team's skilled players gets hit hard or someone gets hit by what the team perceives as a dirty hit. Amateur recreation level players who play strictly inline hockey never consider fisticuffs a legitimate behavior. The amateur game penalizes fisticuffs more harshly, as a player who receives a fighting major is also assessed at least a 10-minute misconduct penalty or a game misconduct penalty and suspension. Most local recreation leagues also suspend or ban players who engage in fights.\n",
      "A professional game consists of two halves of twenty minutes each, the clock running only when the puck is in play. The teams change ends for the second half, and again at the start of each overtime played (playoffs only; same ends as the second half otherwise). Some leagues such as the American Inline Hockey League (AIHL), recreational leagues and children's leagues often play shorter games, generally with two shorter periods or three running clock periods of play.\n",
      "Various procedures are used if a game is tied. Some leagues and tournaments do not use an overtime, unless a \"winner\" must be determined, such as in tournament pool play and league regular season. Others will us either one, or a combination of; sudden death overtime periods, or penalty shootouts. Usually up to two 5-minute sudden death overtimes are played; if still tied, penalty shootouts.\n",
      "Indoor inline hockey is played on any suitable non-slip surface. While converted roller rinks may use wooden floors, dedicated inline hockey facilities use Sport Court or similar surface, which allows maximum traction to inline hockey wheels whilst providing a smooth, unbroken gliding surface for the puck. The playing area should be surrounded by full boards similar to ice hockey with glass or fencing to a height of around 2m. Often, especially in European countries, the game is played in indoor sports halls, on wooden floors. Therefore, there will be no standardized boards but instead the perimeter of the playing surface will be brick walls. In such cases, the corners of the hall are rounded off with added curved boards.\n",
      "Based on Ice Sledge Hockey, Inline Sledge Hockey is played to the same rules as Inline Puck Hockey (essentially ice hockey played off ice using inline skates) and has been made possible by the design and manufacture of inline sledges by RGK, Europe’s premier sports wheelchair maker.\n",
      "There is no classification points system dictating who can be involved in play within Inline Sledge Hockey unlike other team sports such as Wheelchair Basketball and Wheelchair Rugby. Inline Sledge Hockey is being developed to allow everyone, regardless of whether they have a disability or not, to complete up to World Championship level based solely on talent and ability. This makes Inline Sledge Hockey truly inclusive.\n",
      "The first game of Inline Sledge Hockey was played at Bisley, England on 19 December 2009 between the Hull Stingrays and the Grimsby Redwings. Matt Lloyd (Paralympian) is credited with inventing Inline Sledge Hockey and Great Britain is seen as the international leader in the games development.\n",
      "Street hockey is a form of inline hockey played as pick-up hockey on streets[5] or parking lots. Street hockey tends to have very relaxed rules, as any pickup street game or sport would have.\n",
      "Blind inline hockey is also played by athletes who are totally blind or visually impaired. Sighted players can also play, as all players must play while wearing opaque goggles, making all play sightless and \"evening the playing field.\" The blind game is best played on a smaller, cross-floor sized surface (85' by 60') with 4 skaters-and-a-goalie as regular sighted inline hockey.\n",
      "The puck and goals each have a sounding device that enable the players to hear the puck and orient themselves to direction on the playing surface. The players constantly communicate to their teammates regarding their actions and positions on the floor enabling teamwork and playmaking. A sighted referee directs stoppages and restarts. All usual inline hockey rules apply to blind play.\n",
      "There are two lines of sanctioning bodies for inline hockey: those that are related to the roller sports community and those related to the ice hockey community. The International Ice Hockey Federation organizes IIHF Inline Hockey World Championships but the sport is recognized as being governed by the International Roller Sports Federation which organizes FIRS Inline Hockey World Championships.\n",
      "USA Roller Sports is sanctioned by the International Olympic Committee to oversee roller sports. See the related links below for national bodies and further information.\n"
     ]
    }
   ],
   "source": [
    "driver_2 = webdriver.Firefox()\n",
    "driver_2.get('https://www.google.com/')\n",
    "assert 'Google' in driver_2.title\n",
    "select = driver_2.find_element_by_id('lst-ib')\n",
    "select.send_keys('hockey')\n",
    "select.send_keys(Keys.RETURN)\n",
    "driver_2.implicitly_wait(5)\n",
    "hockey_wik = driver_2.find_element_by_link_text('Hockey - Wikipedia')\n",
    "hockey_wik.click()\n",
    "inline= driver_2.find_element_by_css_selector('li.toclevel-2:nth-child(4)')\n",
    "inline.click()\n",
    "driver_2.implicitly_wait(10)\n",
    "main_inline_link = driver_2.find_element_by_link_text('Roller in-line hockey')\n",
    "main_inline_link.click()\n",
    "url = driver_2.current_url\n",
    "parge = requests.get(url)\n",
    "soup = BeautifulSoup(parge.content, 'html.parser')\n",
    "for i in soup.find_all('p'):\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pages must be open first\n",
    "driver.close()\n",
    "driver_2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)https://economictimes.indiatimes.com/definition/selenium-web-driver\n",
    "\n",
    "2)https://www.guru99.com/introduction-webdriver-comparison-selenium-rc.html\n",
    "\n",
    "3)https://www.dataquest.io/blog/web-scraping-tutorial-python/\n",
    "\n",
    "4)https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
