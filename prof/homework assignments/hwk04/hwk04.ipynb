{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 04\n",
    "### Math 5364 - Data Mining 1, Fall 2017, Tarleton State Univ, Dr. Scott Cook\n",
    "### Due Friday 10/27/2017 at midnight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this homework is to explore Naive Bayes and cross-validation.\n",
    "- Get the House Votes 84 data set from the UCI machine learning archive\n",
    "1. Write a Naive Bayes Classifier to predict party affliation from the voting record of a congress person.\n",
    "  - Though NB is one of our simpler classifiers, this is still a non-trivial task.  I'll give you substantial starter code below.\n",
    "  - You may use the MultinomialNB classifier in Scikit learn to check your work.  Note that you may not get *exactly* the same predictions and posterior because scikit learn implements some more advanced refinements, like Laplace smoothing (in the alpha parameter).\n",
    "- Train and test with the entire data set at first, as you validate your code against scikit learn.\n",
    "2. Now, write code to implement $k$-fold cross validation for *your* NB classifier.\n",
    "  - From now on, set seed = 42, for convenient comparisions with your classmates.\n",
    "  - Create a plot:\n",
    "    - Let $k$ range over the integers $5 \\leq k \\leq 145$ that divide 435.  Note that $435/k$ = number of obervations in the testing set; it ranges from 87 to 3.  Plot $435/k$ on the horizontal axis.\n",
    "    - mean accuracy score when using that value of $k$ on the vertical.\n",
    "3. Now, write code to implement delete-$d$ cross validation for *your* NB classifier.  Let $d$ range over the integers $3 \\leq d \\leq 87$ that divide 435.  Repeat $b=10$ times for each value of $d$.  Create a similar plot as above with $d$ on the the horizontal.\n",
    "4. Now write code to implement bootstap cross-validation.  (Recall, unlike the prior methods, this one samples *with* replacement).  Here, we always resample $n=435$ times to make the training set, and test on the observations that never were selected.  Let $b=100$ be the numbers of validation cycles.  Compute accuracy in 2 ways\n",
    "  - As normal: Compute accuracy on the testing set for each bootrap sample, then take the mean.\n",
    "  - Using the 632 correction discussed\n",
    "    - Original source - http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf\n",
    "    - More readable exposition - http://www3.cs.stonybrook.edu/~cse634/lecture_notes/07testing.pdf\n",
    "    - Many other places - make use of reliable internet resources\n",
    "  - Evaluate the 632 correction in light of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-0a61f8a5462e>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-0a61f8a5462e>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    Y = df.loc????\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from setup import *\n",
    "\n",
    "na_legal = True\n",
    "\n",
    "df = pd.read_csv('house-votes-84.csv', header=-1)\n",
    "if(na_legal == True):\n",
    "    df.replace('?','z', inplace=True)\n",
    "else:\n",
    "    df.replace('?' ,np.nan, inplace=True)\n",
    "\n",
    "X_orig = df.loc[:,1:]\n",
    "X = pd.get_dummies(X_orig)\n",
    "Y = df.loc????\n",
    "labels = sorted(Y.unique())\n",
    "\n",
    "def vc(x):\n",
    "    return x.value_counts(normalize=True)\n",
    "prior = vc(Y)\n",
    "\n",
    "def f(grp):\n",
    "    return pd.concat([vc(col[1]) for col in grp.items()], ????)\n",
    "\n",
    "marginals = X_orig.groupby(Y).????.unstack()\n",
    "#Next line makes columns names in marginals match those in X\n",
    "marginals.columns = ['_'.join(map(str,col)) for col in marginals.columns]\n",
    "\n",
    "# NB demands that we multiply the marginals.  But, it is a bad idea to multiplt\n",
    "# a bunch of number together in a computer.  If they are big, the product can overflow\n",
    "# and create errors.  If the numbers are small, they can drop into \"rounding error\" and \n",
    "# again create errors.  So, when we are asked to multiply a bunch of numbers, we often use\n",
    "# the log trick.  Recall that the log of things multiplied equals the sum of their logs.\n",
    "# So, we do a*b*c*d...*z = e^(ln(a*b*c*d*...*z)) = e^(ln(a)+ln(b)+ln(c)+ln(d)+...+ln(z)).\n",
    "# The sum of logs does not grow/shrink as fast as the product, so we often avoid\n",
    "# overflow/rounding errors.\n",
    "log_marginals = ????\n",
    "\n",
    "# Picks out the numbers we need from log_marginals\n",
    "log_posterior = ????.dot(????.T)\n",
    "log_posterior = log_posterior + ????\n",
    "posterior = np.exp(log_posterior)\n",
    "# normalize\n",
    "posterior = posterior.div(posterior.sum(axis=1), axis=0)\n",
    "pred = posterior.idxmax(axis=1)\n",
    "\n",
    "my_posterior = posterior.copy()\n",
    "my_pred = pred.copy()\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Another reason our NB did not match sk_learns NB is that sk_learn uses a\n",
    "# \"smoothing\" process.  Setting alpha = 0 turns that off.  Now, that process may\n",
    "# be very helpful.  I'm turning it off only to show that sk_learn and our code agree.\n",
    "model = MultinomialNB(alpha=0.0)\n",
    "model.????\n",
    "skl_posterior = model.predict_proba(????)\n",
    "skl_posterior = pd.DataFrame(skl_posterior,columns=labels) \n",
    "skl_pred = model.predict(X)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def assess(pred):\n",
    "    mat = confusion_matrix(Y, pred, labels)\n",
    "    sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('true label')\n",
    "    plt.ylabel('predicted label')\n",
    "    plt.show()    \n",
    "    print(\"accuracy = %f\",mat.????.sum()/mat.sum()*100)\n",
    "\n",
    "assess(my_pred)\n",
    "assess(skl_pred)\n",
    "\n",
    "    \n",
    "cls = pd.DataFrame()\n",
    "cls['true'] = Y.copy()\n",
    "cls['my_pred'] = my_pred.copy()\n",
    "cls['im_right'] = ????\n",
    "cls = pd.concat([cls,my_posterior],axis=1)\n",
    "\n",
    "cls['skl_pred'] = skl_pred.copy()\n",
    "cls['skl_right'] = ????\n",
    "cls = pd.concat([cls,skl_posterior],axis=1)\n",
    "\n",
    "cls['pred_same'] = ????\n",
    "cls['close_call'] = (np.abs(my_posterior.iloc[:,0] - my_posterior.iloc[:,1]) <= 0.4)\n",
    "diffus = np.linalg.norm(my_posterior-skl_posterior, axis=1)\n",
    "biggus_diffus = np.argsort(diffus)[::-1][:5]\n",
    "\n",
    "print(\"Skl and I made different predictions\")\n",
    "display(cls.loc[????,:],'all')\n",
    "print(\"I'm wrong\")\n",
    "display(cls.loc[????,:],'all')\n",
    "print(\"Close call\")\n",
    "display(cls.loc[cls['close_call'],:],'all')\n",
    "print(\"Biggus Diffus between skl and me\")\n",
    "display(cls.loc[biggus_diffus,:],'all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
